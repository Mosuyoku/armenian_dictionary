{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "d48af227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "26f289a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(url):\n",
    "    page = requests.get(url)\n",
    "    return BeautifulSoup(page.content, 'html.parser')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6de3eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(soup):\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "            script.extract()\n",
    "            \n",
    "    text = soup.get_text()\n",
    "    return re.sub(r\"\\s+\", \" \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6c604667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(soup):\n",
    "    links = []\n",
    "    links_clear = []\n",
    "\n",
    "    for a in soup.find_all('a', href=True):\n",
    "        links.append(a['href'])    \n",
    "        \n",
    "    for link in links:\n",
    "        if \"http\" in link: \n",
    "            if link.startswith(\"https://www.sdglab.am\"):\n",
    "                links_clear.append(link)\n",
    "            \n",
    "    return list(set(links_clear))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f40acdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_list(scrapped_website):\n",
    "    word_list = []\n",
    "    for x in scrapped_website:\n",
    "        for li in x.split(\" \"):\n",
    "            if re.match(r'[\\u0561-\\u0587\\u0531-\\u0556]', li):\n",
    "                word_list.append(li)\n",
    "            \n",
    "    clear_word_list = []\n",
    "    for word in word_list:\n",
    "        for ch in [' ', ',', '.', '․', '?', '!', '։', ':', '-', '«', '»', '՛', '՝', '`', '(', ')', '/']:\n",
    "            if ch in word:\n",
    "                word = word.replace(ch, ' ')\n",
    "        clear_word_list.extend(word.split(\" \"))\n",
    "\n",
    "    clear_word_list = [x for x in clear_word_list if len(x) > 0]\n",
    "    for cwl in range(len(clear_word_list)):\n",
    "        clear_word_list[cwl] = clear_word_list[cwl].lower()\n",
    "    clear_word_list = set(clear_word_list)\n",
    "    clear_word_list = sorted(clear_word_list)\n",
    "    return clear_word_list[1:]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "c4d7c270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_file(word_list, file_name):\n",
    "    with open(file_name, 'w') as file:\n",
    "        for wl in word_list:\n",
    "            file.write(wl)\n",
    "            file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "df0828d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_name):\n",
    "    with open(file_name) as f:\n",
    "        return [line.rstrip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "2cf2be74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_chunks(li, n):\n",
    "    for i in range(0, len(li), n): \n",
    "        yield li[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "02212c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.sdglab.am/%D5%B6%D5%B8%D6%80%D5%B8%D6%82%D5%A9%D5%B5%D5%B8%D6%82%D5%B6%D5%B6%D5%A5%D6%80'\n",
    "links_buffer = []\n",
    "\n",
    "def scrap_ormian_site(url):\n",
    "\n",
    "    soup = get_content(url)\n",
    "    text = [get_text(soup)]\n",
    "    links = get_links(soup)\n",
    "    links = [x for x in links if x not in links_buffer]\n",
    "    links_buffer.extend(links)\n",
    "    \n",
    "    for link in links:\n",
    "        soup_tmp = get_content(link)\n",
    "        text.append(get_text(soup_tmp))\n",
    "        links_tmp = get_links(soup_tmp)\n",
    "        if len(links_tmp) != 0:\n",
    "            text.extend(scrap_ormian_site(link))\n",
    "\n",
    "    return text\n",
    "\n",
    "scrapped_website = scrap_ormian_site(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "44c69415",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = create_word_list(scrapped_website)\n",
    "save_to_file(word_list, 'armenian_corpus.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "b2a1e5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = read_file('armenian_corpus.txt')\n",
    "    \n",
    "split = []\n",
    "for dc in divide_chunks(lines, 400):\n",
    "    split.append(dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "b7b3fecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Firefox(options=options)\n",
    "\n",
    "with open('armenian_english_corpus.txt', 'a') as file:\n",
    "    for line in split[6]:\n",
    "        glosbe = 'https://glosbe.com/hy/en/'+line\n",
    "        driver.get(glosbe)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html)\n",
    "        div = soup.body.find('h3', attrs={'class': 'translation'})\n",
    "\n",
    "        if div == None:\n",
    "            text = \"-\"\n",
    "        else:\n",
    "            text = div.get_text()\n",
    "            text = re.sub(r\"\\s+\", \" \", text)\n",
    "            text = text.replace(\" \", \"\")\n",
    "        file.write(f'{line}\\t{text}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
